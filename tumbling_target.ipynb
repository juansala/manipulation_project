{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "eeMrMI0-1Dhu",
    "cell_id": "00000-8ff4b16f-28b2-480e-9adb-e2d973ac3635",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "41e5e7bf",
    "execution_start": 1639085077861,
    "execution_millis": 1715,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "from IPython.display import display, SVG\nimport numpy as np\nimport time\nimport os\nimport pydot\nimport sys\n\nfrom pydrake.all import (\n    Adder, AddMultibodyPlantSceneGraph, Demultiplexer, DiagramBuilder, \n    InverseDynamicsController, MakeMultibodyStateToWsgStateSystem, \n    MeshcatVisualizerCpp, MultibodyPlant,Parser, PassThrough, \n    SchunkWsgPositionController, StateInterpolatorWithDiscreteDerivative,\n    Sphere, Cylinder, Box, RigidTransform, SpatialVelocity, Simulator,\n    ConstantVectorSource, LeafSystem, BasicVector, Integrator, JacobianWrtVariable,\n    MeshcatVisualizerParams, RotationMatrix, PiecewisePose, PiecewisePolynomial, \n    TrajectorySource, FindResourceOrThrow, PiecewiseQuaternionSlerp\n)\nfrom manipulation.meshcat_cpp_utils import StartMeshcat, AddMeshcatTriad\nfrom manipulation.scenarios import AddIiwa, AddWsg, AddRgbdSensors, AddShape\nfrom manipulation.utils import FindResource\nfrom manipulation import running_as_notebook\nfrom pydrake.examples.manipulation_station import ManipulationStation\n\nif running_as_notebook and sys.platform == \"linux\" and os.getenv(\"DISPLAY\") is None:\n    from pyvirtualdisplay import Display\n    virtual_display = Display(visible=0, size=(1400, 900))\n    virtual_display.start()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00001-11400e86-1054-47a5-aef0-1b15be64ada2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6d42057f",
    "execution_start": 1639085082406,
    "execution_millis": 5,
    "output_cleared": false,
    "deepnote_output_heights": [
     null,
     21.1875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "# Start the visualizer.\nmeshcat = StartMeshcat()",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Meshcat is now available at https://52fe2c12-5462-4de8-b3a8-e001ac600845.deepnoteproject.com\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Table of Contents",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00002-0389eb7f-617d-40d5-8276-c5dc6723a057",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "1. Introduction and overview (context and goals)\n2. References Used\n3. Planning and executing a grasp maneuver\n4. Engaging a tumbling target\n5. Experiments with initial target conditions\n6. Adding random noise\n7. Future improvements",
   "metadata": {
    "tags": [],
    "cell_id": "00003-2dec1a2b-0a7f-4901-80e7-a98b8687e4d9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Introduction and overview",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00004-de4a29b6-ea9b-4a69-9099-6fafc5a9e39f",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# References",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00005-abbf4efc-b711-494c-af80-dbbf18c94bd8",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Environment setup",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00006-df1b0e8d-7aac-44cf-bcf0-e30d601f65d3",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Below is my modified MakeManipulationStation that is initialized with a target cylinder.",
   "metadata": {
    "cell_id": "00002-52ef9b00-e7d6-42c2-bcf0-bd985dbda6fd",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-c02ff458-1ca6-4059-9c48-a96ad5962c94",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d0ab147c",
    "execution_start": 1639085292377,
    "execution_millis": 423,
    "output_cleared": false,
    "deepnote_output_heights": [
     606.1875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "def MakeManipulationStation(time_step=0.002):\n    builder = DiagramBuilder()\n\n    # Add (only) the iiwa, WSG, and cameras to the scene.\n    plant, scene_graph = AddMultibodyPlantSceneGraph(\n        builder, time_step=time_step)\n    iiwa = AddIiwa(plant)\n    wsg = AddWsg(plant, iiwa)\n    # Parser(plant).AddModelFromFile(\n    #     FindResource(\"models/camera_box.sdf\"), \"camera0\")\n    plant.mutable_gravity_field().set_gravity_vector([0, 0, 0])\n\n    # Set up target cylinder\n    mu = 0.9\n    r = 0.03\n    l = 0.15\n    m = 1\n    color = [1, 0, 0, 1]\n    target = AddShape(plant, Cylinder(r, l), name=\"target\", mass=m, mu=mu, color=color)\n\n    # Add floor\n    # ground = AddShape(plant, Box(10,10,2.0), name=\"ground\", mu=mu)\n    # plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"ground\"), RigidTransform(p=[0,0,-1.0]))\n\n    plant.Finalize()\n\n    num_iiwa_positions = plant.num_positions(iiwa)\n\n    # I need a PassThrough system so that I can export the input port.\n    iiwa_position = builder.AddSystem(PassThrough(num_iiwa_positions))\n    builder.ExportInput(iiwa_position.get_input_port(), \"iiwa_position\")\n    builder.ExportOutput(iiwa_position.get_output_port(), \"iiwa_position_command\")\n\n    # Export the iiwa \"state\" outputs.\n    demux = builder.AddSystem(Demultiplexer(\n        2 * num_iiwa_positions, num_iiwa_positions))\n    builder.Connect(plant.get_state_output_port(iiwa), demux.get_input_port())\n    builder.ExportOutput(demux.get_output_port(0), \"iiwa_position_measured\")\n    builder.ExportOutput(demux.get_output_port(1), \"iiwa_velocity_estimated\")\n    builder.ExportOutput(plant.get_state_output_port(iiwa), \"iiwa_state_estimated\")\n\n    # Export the target \"state\" outputs.\n    demux = builder.AddSystem(Demultiplexer(\n        13, 1))\n    builder.Connect(plant.get_state_output_port(target), demux.get_input_port())\n    builder.ExportOutput(demux.get_output_port(7), \"target_angular_vel_x\")\n    builder.ExportOutput(demux.get_output_port(8), \"target_angular_vel_y\")\n    builder.ExportOutput(demux.get_output_port(9), \"target_angular_vel_z\")\n    # builder.ExportOutput(demux.get_output_port(0), \"target_position_measured\")\n    # builder.ExportOutput(demux.get_output_port(1), \"target_velocity_estimated\")\n    # builder.ExportOutput(plant.get_state_output_port(target), \"target_state_estimated\")\n\n    # Make the plant for the iiwa controller to use.\n    controller_plant = MultibodyPlant(time_step=time_step)\n    controller_iiwa = AddIiwa(controller_plant)\n    AddWsg(controller_plant, controller_iiwa, welded=True)\n    controller_plant.Finalize()\n\n    # Add the iiwa controller\n    iiwa_controller = builder.AddSystem(\n        InverseDynamicsController(\n            controller_plant,\n            kp=[2500]*num_iiwa_positions, #2500\n            ki=[1]*num_iiwa_positions,    #1\n            kd=[20]*num_iiwa_positions,   #20\n            has_reference_acceleration=False))\n    iiwa_controller.set_name(\"iiwa_controller\")\n    builder.Connect(\n        plant.get_state_output_port(iiwa), iiwa_controller.get_input_port_estimated_state())\n\n    # Add in the feed-forward torque\n    adder = builder.AddSystem(Adder(2, num_iiwa_positions))\n    builder.Connect(iiwa_controller.get_output_port_control(),\n                    adder.get_input_port(0))\n    # Use a PassThrough to make the port optional (it will provide zero values if not connected).\n    torque_passthrough = builder.AddSystem(PassThrough([0]*num_iiwa_positions))\n    builder.Connect(torque_passthrough.get_output_port(),\n                    adder.get_input_port(1))\n    builder.ExportInput(torque_passthrough.get_input_port(), \n                        \"iiwa_feedforward_torque\")\n    builder.Connect(adder.get_output_port(),\n                    plant.get_actuation_input_port(iiwa))\n\n    # Add discrete derivative to command velocities.\n    desired_state_from_position = builder.AddSystem(\n        StateInterpolatorWithDiscreteDerivative(\n            num_iiwa_positions, time_step, suppress_initial_transient=True))\n    desired_state_from_position.set_name(\"desired_state_from_position\")\n    builder.Connect(desired_state_from_position.get_output_port(),      \n                    iiwa_controller.get_input_port_desired_state())\n    builder.Connect(iiwa_position.get_output_port(), \n                    desired_state_from_position.get_input_port())\n\n    # Export commanded torques.\n    #builder.ExportOutput(adder.get_output_port(), \"iiwa_torque_commanded\")\n    #builder.ExportOutput(adder.get_output_port(), \"iiwa_torque_measured\")\n\n    # Wsg controller.\n    wsg_controller = builder.AddSystem(SchunkWsgPositionController())\n    wsg_controller.set_name(\"wsg_controller\")\n    builder.Connect(\n        wsg_controller.get_generalized_force_output_port(),             \n        plant.get_actuation_input_port(wsg))\n    builder.Connect(plant.get_state_output_port(wsg),\n                    wsg_controller.get_state_input_port())\n    builder.ExportInput(wsg_controller.get_desired_position_input_port(), \n                        \"wsg_position\")\n    builder.ExportInput(wsg_controller.get_force_limit_input_port(),  \n                        \"wsg_force_limit\")\n    wsg_mbp_state_to_wsg_state = builder.AddSystem(\n        MakeMultibodyStateToWsgStateSystem())\n    builder.Connect(plant.get_state_output_port(wsg), \n                    wsg_mbp_state_to_wsg_state.get_input_port())\n    builder.ExportOutput(wsg_mbp_state_to_wsg_state.get_output_port(), \n                         \"wsg_state_measured\")\n    builder.ExportOutput(wsg_controller.get_grip_force_output_port(), \n                         \"wsg_force_measured\")\n\n    # Cameras.\n    # AddRgbdSensors(builder, plant, scene_graph)\n\n    # Export \"cheat\" ports.\n    builder.ExportOutput(scene_graph.get_query_output_port(), \"geometry_query\")\n    builder.ExportOutput(plant.get_contact_results_output_port(), \n                         \"contact_results\")\n    builder.ExportOutput(plant.get_state_output_port(), \n                         \"plant_continuous_state\")\n\n    diagram = builder.Build()\n    return diagram, plant\n\ndiagram, plant = MakeManipulationStation()\n\n# display(SVG(pydot.graph_from_dot_data(diagram.GetGraphvizString())[0].create_svg()))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "For this project I will be using a modified version of the IIWAPainter class from the Robot Painter assignment. I call my version the IIWACollector.",
   "metadata": {
    "tags": [],
    "cell_id": "00009-9792857f-adf6-4f05-8b2f-a3858f3e3e77",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-699a4ef1-d342-4298-9093-8d1cd02e4b16",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6eed66f5",
    "execution_start": 1639085292856,
    "execution_millis": 39,
    "deepnote_cell_type": "code"
   },
   "source": "class IIWACollector():\n    def __init__(self, traj=None, traj_wsg=None, X_WT=RigidTransform(p=[1.0,0,1.0]), V_WT=SpatialVelocity(w=[0.0,0.0,0.0], v=[0.0,0.0,0.0])):\n        builder = DiagramBuilder()\n        # set up the system of manipulation station\n        station_diagram, self.plant = MakeManipulationStation()\n        self.station = builder.AddSystem(station_diagram)\n        self.iiwa_model_instance = self.plant.GetModelInstanceByName(\"iiwa7\")\n        self.X_WT=X_WT\n        self.V_WT=V_WT\n\n        # optionally add trajectory source\n        if traj is not None:\n            traj_v_G = traj.get_position_trajectory().MakeDerivative()\n            traj_w_G = traj.get_orientation_trajectory().MakeDerivative()\n            v_G_source = builder.AddSystem(TrajectorySource(traj_v_G))\n            w_G_source = builder.AddSystem(TrajectorySource(traj_w_G))\n            self.controller = builder.AddSystem(PseudoInverseController(self.plant))\n            builder.Connect(v_G_source.get_output_port(), self.controller.GetInputPort(\"v_G\"))\n            builder.Connect(w_G_source.get_output_port(), self.controller.GetInputPort(\"w_G\"))\n            self.integrator = builder.AddSystem(Integrator(7))\n            builder.Connect(self.controller.get_output_port(), \n                        self.integrator.get_input_port())\n            builder.Connect(self.integrator.get_output_port(),\n                            self.station.GetInputPort(\"iiwa_position\"))\n            builder.Connect(self.station.GetOutputPort(\"iiwa_position_measured\"),\n                            self.controller.GetInputPort(\"iiwa_position\"))\n        \n        if traj_wsg is not None:\n            wsg_source = builder.AddSystem(TrajectorySource(traj_wsg))\n            wsg_source.set_name(\"wsg_command\")\n            builder.Connect(wsg_source.get_output_port(), self.station.GetInputPort(\"wsg_position\"))\n        else:\n            wsg_position = builder.AddSystem(ConstantVectorSource([0.1]))\n            builder.Connect(wsg_position.get_output_port(), self.station.GetInputPort(\"wsg_position\"))\n\n        params = MeshcatVisualizerParams()\n        params.delete_on_initialization_event = False\n        self.visualizer = MeshcatVisualizerCpp.AddToBuilder(\n            builder, self.station.GetOutputPort(\"geometry_query\"), meshcat, params)\n\n        self.diagram = builder.Build()\n        self.gripper_frame = self.plant.GetFrameByName('body')\n        self.world_frame = self.plant.world_frame()\n\n        context = self.CreateDefaultContext()\n        self.diagram.Publish(context)\n\n    def visualize_frame(self, name, X_WF, length=0.15, radius=0.006):\n        \"\"\"\n        visualize imaginary frame that are not attached to existing bodies\n        \n        Input: \n            name: the name of the frame (str)\n            X_WF: a RigidTransform to from frame F to world.\n        \n        Frames whose names already exist will be overwritten by the new frame\n        \"\"\"\n        AddMeshcatTriad(meshcat, \"painter/\" + name,\n                        length=length, radius=radius, X_PT=X_WF)\n\n    def CreateDefaultContext(self):\n        context = self.diagram.CreateDefaultContext()\n        plant_context = self.diagram.GetMutableSubsystemContext(self.plant,   context)\n        station_context = self.diagram.GetMutableSubsystemContext(self.station, context)\n        # station_context = self.station.GetMyContextFromRoot(self.simulator.get_mutable_context())\n        \n        # provide initial states\n        q0 = np.array([ 1.40666193e-05,  1.56461165e-01, -3.82761069e-05, \n                       -1.32296976e+00, -6.29097287e-06,  1.61181157e+00, -2.66900985e-05])\n        q0_2 = np.array([ 1.40666193e-05,  1.56461165e-01, -3.82761069e-05, \n                       -1.32296976e+00, -6.29097287e-06,  1.61181157e+00, 1])\n        \n        # set the joint positions of the kuka arm\n        self.plant.SetPositions(plant_context, self.iiwa_model_instance, q0)\n\n        # Set target's initial condition (pose and spatial velocity)\n        target = self.plant.GetBodyByName('target')\n        self.plant.SetFreeBodyPose(plant_context, target, X_WB=self.X_WT)\n        self.plant.SetFreeBodySpatialVelocity(context=plant_context, body=target, V_WB=self.V_WT)\n\n        if hasattr(self, 'integrator'):\n            self.integrator.set_integral_value(\n                self.integrator.GetMyMutableContextFromRoot(context), \n                self.plant.GetPositions(plant_context, self.iiwa_model_instance))\n\n        return context\n    \n    def get_X_WG(self, context=None):\n\n        if not context:\n            context = self.CreateDefaultContext()\n        plant_context = self.plant.GetMyMutableContextFromRoot(context)\n        X_WG = self.plant.CalcRelativeTransform(\n                    plant_context,\n                    frame_A=self.world_frame,\n                    frame_B=self.gripper_frame)\n        return X_WG\n\n    def simulate(self):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = 20.0 if running_as_notebook else 0.01\n        simulator.AdvanceTo(duration)\n\n    def short_sim(self):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = 5\n        simulator.AdvanceTo(duration)\n\n    def get_target_location(self):\n        return self.X_WT.p, self.X_WT.R\n\n    def get_diagram(self):\n        return self.diagram",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-46372fba-4cab-4c76-9e5c-02f38ca2cc5b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "27f0d69e",
    "execution_start": 1639085292896,
    "execution_millis": 573,
    "deepnote_output_heights": [
     309.1875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "# meshcat.Delete()\ncollector = IIWACollector(X_WT=RigidTransform(p=[1.0,0,1.0]), V_WT=SpatialVelocity(w=[0.1,0.0,0.0], v=[0.01,0.0,0.0]))\n\ndiagram = collector.get_diagram()\n\n# collector.simulate()\n# display(SVG(pydot.graph_from_dot_data(diagram.GetGraphvizString())[0].create_svg()))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Planning and executing a grasp maneuver",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00005-c41131b3-28bd-4f82-91f6-3fe7908d73de",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "First, we need to provide an inverse kinematics controller and a pose trajectory for the wsg gripper to be at pre-specified grasp pose. This grasp pose is determined by the initial location of the target, and since we are currently assuming that our target pose estimation is perfect then the grasp pose is easy to compute. Also, in this section we will mainly be focusing on grasping a stationary target.\n\nLet's plug in the PseudoInverseController from the Robot Painter assignment as a start.",
   "metadata": {
    "tags": [],
    "cell_id": "00006-20b35ec2-d4e3-41ca-b84d-88876c297119",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-be359ce0-69d8-4f09-ba7e-0647990397d2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "14331735",
    "execution_start": 1639085293480,
    "execution_millis": 6,
    "deepnote_output_heights": [
     606.71875,
     606.71875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "class PseudoInverseController(LeafSystem):\n    \"\"\"\n    same controller seen in 'Robot Painter'\n    \"\"\"\n    def __init__(self, plant):\n        LeafSystem.__init__(self)\n        self._plant = plant\n        self._plant_context = plant.CreateDefaultContext()\n        self._iiwa = plant.GetModelInstanceByName(\"iiwa7\")\n        self._G = plant.GetBodyByName(\"body\").body_frame()\n        self._W = plant.world_frame()\n\n        self.w_G_port = self.DeclareVectorInputPort(\"w_G\", BasicVector(3))\n        self.v_G_port = self.DeclareVectorInputPort(\"v_G\", BasicVector(3))\n        self.q_port = self.DeclareVectorInputPort(\"iiwa_position\", BasicVector(7))\n        self.DeclareVectorOutputPort(\"iiwa_velocity\", BasicVector(7), \n                                     self.CalcOutput)\n        self.iiwa_start = plant.GetJointByName(\"iiwa_joint_1\").velocity_start()\n        self.iiwa_end = plant.GetJointByName(\"iiwa_joint_7\").velocity_start()\n\n    def CalcOutput(self, context, output):\n        w_G = self.w_G_port.Eval(context)\n        v_G = self.v_G_port.Eval(context)\n        V_G = np.hstack([w_G, v_G])\n        q = self.q_port.Eval(context)\n        self._plant.SetPositions(self._plant_context, self._iiwa, q)\n        J_G = self._plant.CalcJacobianSpatialVelocity(\n            self._plant_context, JacobianWrtVariable.kV, \n            self._G, [0,0,0], self._W, self._W)\n        J_G = J_G[:,self.iiwa_start:self.iiwa_end+1] # Only iiwa terms.\n        v = np.linalg.pinv(J_G).dot(V_G) #important\n        output.SetFromVector(v)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To verify that my modified system is working, let's run a the circular trajectory example from the same Robot Painter assignment. Running the cell below should draw the circular trajectory of keyframes that we saw in the assignment.",
   "metadata": {
    "tags": [],
    "cell_id": "00014-6fa64307-dceb-4fd0-a2d3-52a7ca141451",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00018-3c702e9c-4a52-4c19-b3bd-2033988d2886",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f6f1cea7",
    "execution_start": 1639085293619,
    "execution_millis": 509,
    "deepnote_cell_type": "code"
   },
   "source": "X_WorldGripper_init = collector.get_X_WG()\n\n# # define center and radius\nradius = 0.1\np0 = [0.45, 0.0, 0.4]\nR0 = RotationMatrix(np.array([[0, 1, 0], [0, 0, -1], [-1, 0, 0]], dtype=np.float).T)\nX_WorldCenter = RigidTransform(R0, p0)\nnum_key_frames = 10\n\"\"\"\nyou may use different thetas as long as your trajectory starts\nfrom the Start Frame above and your rotation is positive\nin the world frame about +z axis\nthetas = np.linspace(0, 2*np.pi, num_key_frames)\n\"\"\"\nthetas = np.linspace(0, 2*np.pi, num_key_frames)\n\ndef compose_circular_key_frames(thetas, X_WorldCenter, X_WorldGripper_init):\n    \"\"\"    \n    returns: a list of RigidTransforms\n    \"\"\"\n    ## this is an template, replace your code below\n    key_frame_poses_in_world = [X_WorldGripper_init]\n    for theta in thetas:\n        p_next_frame = np.array(p0) + np.array([radius*np.cos(theta), radius*np.sin(theta), 0])\n        R_next_frame = RotationMatrix.MakeYRotation(-np.pi/2) @ RotationMatrix.MakeZRotation(np.pi/2) @ RotationMatrix.MakeYRotation(-theta)\n        next_pose = RigidTransform(R_next_frame, p_next_frame)\n        key_frame_poses_in_world.append(next_pose)\n        \n    return key_frame_poses_in_world\n\n# check key frames instead of interpolated trajectory\ndef visualize_key_frames(frame_poses):\n    for i, pose in enumerate(frame_poses):\n        collector.visualize_frame('frame_{}'.format(i), pose, length=0.05)\n\nkey_frame_poses = compose_circular_key_frames(thetas, X_WorldCenter, X_WorldGripper_init)  \ntimes = np.linspace(0, 20, num_key_frames+1)\ntraj = PiecewisePose.MakeLinear(times, key_frame_poses)\n\n# Initialize target pose and spatial velocity\np_target = np.array([0.55,0.55,0.8])\nR_target = RotationMatrix()\nw_target = [0.0,0.0,0.0]\nv_target = [0.0,0.0,0.0]\nX_WT=RigidTransform(R_target, p_target) \nV_WT=SpatialVelocity(w_target, v_target)\ncollector = IIWACollector(traj=traj, X_WT=X_WT, V_WT=V_WT)\n\nvisualize_key_frames(key_frame_poses)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "<ipython-input-7-22ce61b5d155>:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  R0 = RotationMatrix(np.array([[0, 1, 0], [0, 0, -1], [-1, 0, 0]], dtype=np.float).T)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Final sanity check! Let's execute the circular trajectory.",
   "metadata": {
    "tags": [],
    "cell_id": "00017-4387d3ae-a0a0-431a-a6cf-ea30a5e48930",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00019-5228e3f8-8e76-468c-8c25-2a077963be06",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5e4c7cc0",
    "execution_start": 1639085294132,
    "execution_millis": 19988,
    "deepnote_cell_type": "code"
   },
   "source": "collector.simulate()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Given the initial pose of the target, let's visualize the desired gripper pre-grasp pose (in the world frame) using a keyframe. Running the cell below draws the keyframe in the meshcat visualizer. The following function 'visualize_frame' comes from the Robot Painter problem set.",
   "metadata": {
    "tags": [],
    "cell_id": "00014-35c3f404-bf5d-4dc3-93ac-cb41d11f2efb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-9a941666-12f7-4fe7-a9f7-6fca1f2b2da6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "305be1a9",
    "execution_start": 1639085314130,
    "execution_millis": 4,
    "deepnote_output_heights": [
     155.59375
    ],
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize environment\n# collector = IIWACollector(traj, X_WT, V_WT)\n\n# Compute pre-grasp pose\np_pre_grasp = p_target + np.array([0.0, -0.15, 0.0])\nR_pre_grasp = RotationMatrix.MakeYRotation(np.pi)\n# R_pre_grasp = RotationMatrix(np.array([[0, 1, 0], [0, 0, -1], [-1, 0, 0]], dtype=np.float).T)\nX_pre_grasp = RigidTransform(R_pre_grasp, p_pre_grasp)\n# X_pre_grasp = X_WT\n\ncollector.visualize_frame('pre_grasp', X_pre_grasp)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now that we've defined the pre-grasp pose, let's generate a new trajectory like in the circular example.",
   "metadata": {
    "tags": [],
    "cell_id": "00021-1f8b5f3c-2751-43aa-9de2-b7d7010ed5bc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00022-cce4a0b4-6443-416c-a490-e58480825413",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "28fe8c70",
    "execution_start": 1639085314426,
    "execution_millis": 321,
    "deepnote_cell_type": "code"
   },
   "source": "X_WorldGripper_init = collector.get_X_WG()\nnum_key_frames = 1\n\ndef compose_traj_key_frames(X_WorldGripper_init):\n    return [X_WorldGripper_init, X_pre_grasp]\n\nkey_frame_poses = compose_traj_key_frames(X_WorldGripper_init)  \ntimes = np.linspace(0, 20, num_key_frames+1)\n# print(times)\ntraj = PiecewisePose.MakeLinear(times, key_frame_poses)\n\n# Re-initialize environment\ncollector = IIWACollector(traj=traj, X_WT=X_WT, V_WT=V_WT)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00023-d715f67d-8a70-44f1-8435-82ebda3e5303",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5e4c7cc0",
    "execution_start": 1639085314782,
    "execution_millis": 19983,
    "deepnote_cell_type": "code"
   },
   "source": "collector.simulate()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "In this next section, we'll try performing a more effective interpolation approach while also clearly defining the phases in the trajectory and executing the full thing.\n\nThe maneuver can  be broken down like this:\n1) Initial - gripper is at initial pose X_G_init, target is at initial pose X_T_init\n2) Pre-grasp - gripper is at pre-grasp pose (relative to the target) X_T_Gpregrasp, target is still at pose X_T_init\n3) Grasp - gripper is at grasp pose (relative to the target) X_T_Ggrasp, target is still at pose X_T_init\n\nFirst, we need to define these frames in order to later assign them timestamps. This cell below is modified from the Chapter 3 notebook on Pick and Place methods.",
   "metadata": {
    "tags": [],
    "cell_id": "00024-ec48f928-c13d-432f-98e5-882c4461bfe9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-b92ec54d-fd0d-446b-bbb8-2a163db49589",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8053e3ca",
    "execution_start": 1639085334782,
    "execution_millis": 12,
    "deepnote_cell_type": "code"
   },
   "source": "def make_gripper_frames(X_G, X_O, target_clearance=np.array([0.0, 0.08, 0.0]), R_GgraspTarget=RotationMatrix.MakeYRotation(np.pi).MakeZRotation(-np.pi/4).inverse()):\n  \"\"\"\n  Takes a partial specification with X_G[\"initial\"] and X_O[\"initial\"] and X_0[\"goal\"], and \n  returns a X_G and times with all of the pick and place frames populated.\n  \"\"\"\n  # Define (again) the gripper pose relative to the object when in grasp.\n  p_GgraspO = target_clearance\n  R_GgraspO = R_GgraspTarget\n  # R_GgraspO = RotationMatrix.MakeZRotation(np.pi/2) #.MakeZRotation(-np.pi/4).inverse()\n  X_GgraspO = RigidTransform(R_GgraspO, p_GgraspO)\n  X_OGgrasp = X_GgraspO.inverse()\n  # pregrasp is negative y in the gripper frame (see the figure!).\n  X_GgraspGpregrasp = RigidTransform(p=[0, -0.2, 0])\n\n  X_G[\"pick\"] = X_O[\"initial\"].multiply(X_OGgrasp)\n  X_G[\"prepick\"] = X_G[\"pick\"].multiply(X_GgraspGpregrasp)\n  X_G[\"adjusted\"] = X_G[\"prepick\"]\n  X_G[\"postpick\"] = X_G[\"pick\"]\n\n  # Now let's set the timing\n  times = {\"initial\": 0}\n  X_GinitialGprepick = X_G[\"initial\"].inverse().multiply(X_G[\"prepick\"])\n  times[\"prepick\"] = times[\"initial\"] + 15.0*np.linalg.norm(X_GinitialGprepick.translation())\n  times[\"adjusted\"] = times[\"prepick\"] + 2.0\n  # Allow some time for the gripper to close.\n  times[\"pick_start\"] = times[\"adjusted\"] + 7.0\n  times[\"pick_end\"] = times[\"pick_start\"] + 2.0\n  times[\"postpick\"] = times[\"pick_end\"] + 2.0\n\n  return X_G, times\n\n# Re-initialize environment\np_target = np.array([0.5,0.5,0.8])\nR_target = RotationMatrix()\nw_target = [0.0,0.0,0.0]\nv_target = [0.0,0.0,0.0]\nX_WT=RigidTransform(R_target, p_target) \nV_WT=SpatialVelocity(w_target, v_target)\n\nX_G = {\"initial\": X_WorldGripper_init}\nX_O = {\"initial\": X_WT, \"goal\": X_WT}\nX_G, times = make_gripper_frames(X_G, X_O)\n# print(X_G)\n# print(times)\nprint(f\"Sanity check: The entire maneuver will take {times['postpick']} seconds to execute.\")",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Sanity check: The entire maneuver will take 19.16613355823499 seconds to execute.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Let's visualize the frames to make sure they are correct.",
   "metadata": {
    "tags": [],
    "cell_id": "00026-49ee8129-f4c9-47a6-8d61-36f5a9c93503",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00027-496bcb63-9f13-46fb-bfcd-1d5351707372",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "57a652bd",
    "execution_start": 1639085334783,
    "execution_millis": 397,
    "deepnote_cell_type": "code"
   },
   "source": "def visualize_gripper_frames(X_G, X_O):\n    builder = DiagramBuilder()\n\n    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step = 0.0)\n    parser = Parser(plant, scene_graph)\n    gripper = FindResourceOrThrow(\n        \"drake/manipulation/models/wsg_50_description/sdf/schunk_wsg_50_no_tip.sdf\")\n    mu = 0.5\n    r = 0.03\n    l = 0.15\n    m = 1\n    color = [1, 0, 0, 1]\n    AddShape(plant, Cylinder(r, l), name=\"target\", mass=m, mu=mu, color=color)\n    for key, pose in X_G.items():\n      g = parser.AddModelFromFile(gripper, f\"gripper_{key}\")\n      plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"body\", g), pose)\n    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"target\"), X_WT)\n\n    plant.Finalize()\n\n    meshcat.Delete()\n    visualizer = MeshcatVisualizerCpp.AddToBuilder(\n        builder, scene_graph, meshcat)\n\n    diagram = builder.Build()\n    context = diagram.CreateDefaultContext()\n    diagram.Publish(context)\n\nvisualize_gripper_frames(X_G, X_O)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Next is constructing the position trajectory like we did before with PiecewisePose.MakeLinear, however now PiecwisePolynomial.",
   "metadata": {
    "tags": [],
    "cell_id": "00028-b8030f1a-6f37-4d1a-afb3-235fab56cc8b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00029-5eff05f3-5628-468a-8afb-9add0f8fa6c2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "33eb93fb",
    "execution_start": 1639085335189,
    "execution_millis": 5,
    "deepnote_output_heights": [
     290
    ],
    "deepnote_cell_type": "code"
   },
   "source": "def make_gripper_position_trajectory(X_G, times):\n    \"\"\"\n    Constructs a gripper position trajectory from the plan \"sketch\".\n    \"\"\"\n    traj = PiecewisePolynomial.FirstOrderHold(\n        [times[\"initial\"], times[\"prepick\"]], np.vstack([X_G[\"initial\"].translation(), X_G[\"prepick\"].translation()]).T)\n\n    traj.AppendFirstOrderSegment(times[\"adjusted\"], X_G[\"adjusted\"].translation())\n    traj.AppendFirstOrderSegment(times[\"pick_start\"], X_G[\"pick\"].translation())\n    traj.AppendFirstOrderSegment(times[\"pick_end\"], X_G[\"pick\"].translation())\n    traj.AppendFirstOrderSegment(times[\"postpick\"], X_G[\"pick\"].translation())\n\n    return traj\n\ntraj_p_G = make_gripper_position_trajectory(X_G, times)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Similarly, we construct the orientation trajectory.",
   "metadata": {
    "tags": [],
    "cell_id": "00030-621169a7-0cdf-45db-8287-be9bf1843b5a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00031-0d69f710-ca42-432a-982d-fc6e932da37b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6e0acfc9",
    "execution_start": 1639085335207,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "def make_gripper_orientation_trajectory(X_G, times):\n    \"\"\"\n    Constructs a gripper position trajectory from the plan \"sketch\".\n    \"\"\"\n    traj = PiecewiseQuaternionSlerp();\n    traj.Append(times[\"initial\"], X_G[\"initial\"].rotation())\n    traj.Append(times[\"prepick\"], X_G[\"prepick\"].rotation())\n    traj.Append(times[\"adjusted\"], X_G[\"adjusted\"].rotation())\n    traj.Append(times[\"pick_start\"], X_G[\"pick\"].rotation())\n    traj.Append(times[\"pick_end\"], X_G[\"pick\"].rotation())\n    traj.Append(times[\"postpick\"], X_G[\"pick\"].rotation())\n\n    return traj\n\ntraj_R_G = make_gripper_orientation_trajectory(X_G, times)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now we construct the gripper trajectory.",
   "metadata": {
    "tags": [],
    "cell_id": "00032-ba99a785-c35b-47f1-838e-b75dd350cb6c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-b5da4824-11c9-432a-9b65-4bbe8a5ff3fa",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e63db23e",
    "execution_start": 1639085335215,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "opened = np.array([0.107]);\nclosed = np.array([0.0]);\n\ndef make_wsg_command_trajectory(times):\n    traj_wsg_command = PiecewisePolynomial.FirstOrderHold(\n        [times[\"initial\"], times[\"pick_start\"]], np.hstack([[opened], [opened]]))\n    traj_wsg_command.AppendFirstOrderSegment(times[\"pick_end\"], closed)\n    return traj_wsg_command\n\ntraj_wsg_command = make_wsg_command_trajectory(times)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's try executing the full trajectory now.",
   "metadata": {
    "tags": [],
    "cell_id": "00032-54d6199f-9121-443c-b66c-bece6102e887",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00033-5ecc101a-7c2f-436c-b696-261557e0766a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e108c2f5",
    "execution_start": 1639085335220,
    "execution_millis": 606,
    "deepnote_output_heights": [
     606.1875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "traj = PiecewisePose(traj_p_G, traj_R_G)\n\n# meshcat.Delete()\ncollector = IIWACollector(traj, traj_wsg_command, X_WT, V_WT)\n# diagram = collector.get_diagram()\n# display(SVG(pydot.graph_from_dot_data(diagram.GetGraphvizString())[0].create_svg()))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00034-888a59e1-9a6a-48eb-a1ad-81a696243584",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5e4c7cc0",
    "execution_start": 1639085335837,
    "execution_millis": 20043,
    "deepnote_cell_type": "code"
   },
   "source": "collector.simulate()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "While there are still some kinks in the pick-and-place pipeline, including some deviation from the desired poses, the task of grasping a free floating object is achievable. Unfortunately, to make this work I needed to experiment with various initial positions for the target and with the interpolated frame intervals. My current best explanation for the difficulty in getting this to work robustly is that the robot is encountering singularities or saturated joint velocities, which could be addressed using an DiffIKQP formulation. Also gravity is turned off, so...",
   "metadata": {
    "tags": [],
    "cell_id": "00037-f753c3bf-75cc-433b-b4e1-7fc2c6de8128",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Engaging with a tumbling target",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00038-639d2edb-f5f2-4f5f-b360-519fc9acd05e",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Now we'll try catching the target again, but with a few new cases:\n1) the target will have some pre-specified rotational velocity (about the target's x-axis)\n2) the target will have some pre-specified linear velocity\n3) the target will have some combination of initial rotational and linear velocity\n\nTackling case #1 will require some changes to the WSG controller, in particular there's a need to drive the gripper rotational velocity to match the target's in order to successfully grasp it. Because we still know the target's state perfectly, we know the rotational velocity at all times and now we just need to use that as an input to our new WSG controller. One last important detail, however, is that we also need to align the gripper's rotation to grasp the target on its round face, as opposed to grasping it from the ends.",
   "metadata": {
    "tags": [],
    "cell_id": "00039-653d3b20-10e4-4c24-90ad-0801bf29e59e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00040-198aa736-4282-4dc2-822f-09a384767ddc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "72e94d29",
    "execution_start": 1639085355880,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "class CollectorPlanner(LeafSystem):\n    ''' Effectively acts as a custom TrajectorySource\n    '''\n    def __init__(self, plant, traj, poses, times, output_vel):\n        LeafSystem.__init__(self)\n        self._plant = plant\n        self._plant_context = plant.CreateDefaultContext()\n        self._iiwa = plant.GetModelInstanceByName(\"iiwa7\")\n        self._G = plant.GetBodyByName(\"body\").body_frame()\n        self._W = plant.world_frame()\n        \n        assert traj.cols() == 1\n        port = self.DeclareVectorOutputPort(\"value\", traj.rows(), self.CalcOutput)\n        port.disable_caching_by_default()\n        self.w_x_port = self.DeclareVectorInputPort(\"target_rotation_rate_x\", BasicVector(1))\n        self.w_y_port = self.DeclareVectorInputPort(\"target_rotation_rate_y\", BasicVector(1))\n        self.w_z_port = self.DeclareVectorInputPort(\"target_rotation_rate_z\", BasicVector(1))\n        # Keep the trajectory as undeclared state\n        self.traj = traj\n        self.match_time = times['adjusted']\n        self.updated = False\n        self.w_cyl = None\n        self.R_WG_adjusted = poses['adjusted'].rotation()\n\n        # Flag to see whether outputting linear or angular velocities\n        self.output_vel = output_vel\n\n    def get_X_WG(self):\n\n        X_WG = self._plant.CalcRelativeTransform(\n                    self._plant_context,\n                    frame_A=self._W,\n                    frame_B=self._G)\n        return X_WG\n\n    def CalcOutput(self, context, output):\n        # Note: you can add input ports and read their values here.\n        if (context.get_time() >= times['pick_end']):\n            output.SetFromVector(self.traj.value(context.get_time()))\n        elif (context.get_time() >= self.match_time):\n            target_ang_vel_x = self.w_x_port.Eval(context)\n            target_ang_vel_y = self.w_y_port.Eval(context)\n            target_ang_vel_z = self.w_z_port.Eval(context)\n            target_ang_vel = np.array([target_ang_vel_x[0], target_ang_vel_y[0], target_ang_vel_z[0]])\n            # print(target_ang_vel)\n\n            # If outputting linear velocity\n            if self.output_vel:\n                lin_vel = np.array([0.0, 0.0, 0.0])\n                # output.SetFromVector(lin_vel)\n                output.SetFromVector(self.traj.value(context.get_time()))\n            # Else if outputting angular velocity\n            else:\n                if self.w_cyl is None:\n                    self.w_cyl = np.linalg.norm(target_ang_vel)\n                ang_vel_y_G = (self.w_cyl * times['adjusted'] + self.w_cyl * (times['pick_start'] - times['adjusted'])) / (times['pick_start'] - times['adjusted'])\n                ang_vel_G = np.array([0, ang_vel_y_G, 0.0])\n                ang_vel = self.R_WG_adjusted.multiply(ang_vel_G)\n                # print(ang_vel)\n                output.SetFromVector(ang_vel)\n        else:\n            output.SetFromVector(self.traj.value(context.get_time()))\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00042-cfe9edbf-2148-4c13-9e51-049174acd3b0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f85f2a21",
    "execution_start": 1639085355882,
    "execution_millis": 40,
    "deepnote_cell_type": "code"
   },
   "source": "class IIWACollector2():\n    def __init__(self, traj=None, poses=None, times=None, traj_wsg=None, X_WT=RigidTransform(p=[1.0,0,1.0]), V_WT=SpatialVelocity(w=[0.0,0.0,0.0], v=[0.0,0.0,0.0])):\n        builder = DiagramBuilder()\n        # set up the system of manipulation station\n        station_diagram, self.plant = MakeManipulationStation()\n        self.station = builder.AddSystem(station_diagram)\n        self.iiwa_model_instance = self.plant.GetModelInstanceByName(\"iiwa7\")\n        self.X_WT=X_WT\n        self.V_WT=V_WT\n\n        # optionally add trajectory source\n        if traj is not None:\n            traj_v_G = traj.get_position_trajectory().MakeDerivative()\n            traj_w_G = traj.get_orientation_trajectory().MakeDerivative()\n            v_G_source = builder.AddSystem(CollectorPlanner(self.plant, traj_v_G, poses, times, True))\n            w_G_source = builder.AddSystem(CollectorPlanner(self.plant, traj_w_G, poses, times, False))\n            self.controller = builder.AddSystem(PseudoInverseController(self.plant))\n            builder.Connect(v_G_source.get_output_port(), self.controller.GetInputPort(\"v_G\"))\n            builder.Connect(w_G_source.get_output_port(), self.controller.GetInputPort(\"w_G\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_x\"), v_G_source.GetInputPort(\"target_rotation_rate_x\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_x\"), w_G_source.GetInputPort(\"target_rotation_rate_x\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_y\"), v_G_source.GetInputPort(\"target_rotation_rate_y\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_y\"), w_G_source.GetInputPort(\"target_rotation_rate_y\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_z\"), v_G_source.GetInputPort(\"target_rotation_rate_z\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_z\"), w_G_source.GetInputPort(\"target_rotation_rate_z\"))\n            self.integrator = builder.AddSystem(Integrator(7))\n            builder.Connect(self.controller.get_output_port(), \n                        self.integrator.get_input_port())\n            builder.Connect(self.integrator.get_output_port(),\n                            self.station.GetInputPort(\"iiwa_position\"))\n            builder.Connect(self.station.GetOutputPort(\"iiwa_position_measured\"),\n                            self.controller.GetInputPort(\"iiwa_position\"))\n        # handle gripper velocity matching\n            \n        if traj_wsg is not None:\n            wsg_source = builder.AddSystem(TrajectorySource(traj_wsg))\n            wsg_source.set_name(\"wsg_command\")\n            builder.Connect(wsg_source.get_output_port(), self.station.GetInputPort(\"wsg_position\"))\n        else:\n            wsg_position = builder.AddSystem(ConstantVectorSource([0.1]))\n            builder.Connect(wsg_position.get_output_port(), self.station.GetInputPort(\"wsg_position\"))\n\n        params = MeshcatVisualizerParams()\n        params.delete_on_initialization_event = False\n        self.visualizer = MeshcatVisualizerCpp.AddToBuilder(\n            builder, self.station.GetOutputPort(\"geometry_query\"), meshcat, params)\n\n        self.diagram = builder.Build()\n        self.gripper_frame = self.plant.GetFrameByName('body')\n        self.world_frame = self.plant.world_frame()\n\n        context = self.CreateDefaultContext()\n        self.diagram.Publish(context)\n\n    def visualize_frame(self, name, X_WF, length=0.15, radius=0.006):\n        \"\"\"\n        visualize imaginary frame that are not attached to existing bodies\n        \n        Input: \n            name: the name of the frame (str)\n            X_WF: a RigidTransform to from frame F to world.\n        \n        Frames whose names already exist will be overwritten by the new frame\n        \"\"\"\n        AddMeshcatTriad(meshcat, \"painter/\" + name,\n                        length=length, radius=radius, X_PT=X_WF)\n\n    def CreateDefaultContext(self):\n        context = self.diagram.CreateDefaultContext()\n        plant_context = self.diagram.GetMutableSubsystemContext(self.plant,   context)\n        station_context = self.diagram.GetMutableSubsystemContext(self.station, context)\n        # station_context = self.station.GetMyContextFromRoot(self.simulator.get_mutable_context())\n        \n        # provide initial states\n        q0 = np.array([ 1.40666193e-05,  1.56461165e-01, -3.82761069e-05, \n                       -1.32296976e+00, -6.29097287e-06,  1.61181157e+00, -2.66900985e-05])\n        \n        # set the joint positions of the kuka arm\n        self.plant.SetPositions(plant_context, self.iiwa_model_instance, q0)\n\n        # Set target's initial condition (pose and spatial velocity)\n        target = self.plant.GetBodyByName('target')\n        self.plant.SetFreeBodyPose(plant_context, target, X_WB=self.X_WT)\n        self.plant.SetFreeBodySpatialVelocity(context=plant_context, body=target, V_WB=self.V_WT)\n\n        if hasattr(self, 'integrator'):\n            self.integrator.set_integral_value(\n                self.integrator.GetMyMutableContextFromRoot(context), \n                self.plant.GetPositions(plant_context, self.iiwa_model_instance))\n\n        return context\n    \n    def get_X_WG(self, context=None):\n\n        if not context:\n            context = self.CreateDefaultContext()\n        plant_context = self.plant.GetMyMutableContextFromRoot(context)\n        X_WG = self.plant.CalcRelativeTransform(\n                    plant_context,\n                    frame_A=self.world_frame,\n                    frame_B=self.gripper_frame)\n        return X_WG\n\n    def simulate(self):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = 20.0 if running_as_notebook else 0.01\n        simulator.AdvanceTo(duration)\n\n    def simulate_with_duration(self, tiempo):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = tiempo if running_as_notebook else 0.01\n        simulator.AdvanceTo(duration)\n\n    def short_sim(self):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = 5\n        simulator.AdvanceTo(duration)\n\n    def get_target_location(self):\n        return self.X_WT.p, self.X_WT.R\n\n    def get_diagram(self):\n        return self.diagram",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00040-9d6bede7-a4d1-491b-9edf-46460aa2a82c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cd8344a3",
    "execution_start": 1639085356386,
    "execution_millis": 5,
    "deepnote_output_heights": [
     606.1875,
     328.390625
    ],
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize target and motion plan\n\n# p_target = np.array([0.6,0.6,0.8])\np_target = np.array([0.55,0.55,0.8])\nR_target = RotationMatrix()\nw_target = [0.15,0.15,0.0]\nv_target = [0.0,0.0,0.0]\nX_WT=RigidTransform(R_target, p_target) \nV_WT=SpatialVelocity(w_target, v_target)\n\nX_G = {\"initial\": X_WorldGripper_init}\nX_O = {\"initial\": X_WT, \"goal\": X_WT}\nX_G, times = make_gripper_frames(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]))\n# print(X_G)\n# print(times)\nprint(f\"Sanity check: The entire maneuver will take {times['postpick']} seconds to execute.\")\nvisualize_gripper_frames(X_G, X_O)\ntraj_p_G = make_gripper_position_trajectory(X_G, times)\ntraj_R_G = make_gripper_orientation_trajectory(X_G, times)\ntraj_wsg_command = make_wsg_command_trajectory(times)\ntraj = PiecewisePose(traj_p_G, traj_R_G)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Sanity check: The entire maneuver will take 19.384713688718133 seconds to execute.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00043-72f545d9-c54b-444e-bb2c-f1adb3371666",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e2c3fc20",
    "execution_start": 1639085356397,
    "execution_millis": 576,
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize collector (now IIWACollector2)\n\nmeshcat.Delete()\ncollector2 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n# collector.short_sim()\ndiagram = collector2.get_diagram()\n# display(SVG(pydot.graph_from_dot_data(diagram.GetGraphvizString())[0].create_svg()))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Running the cell below demonstrates the iiwa gripper predicting a future target attitude and setting a gripper angular velocity in order to catch the target at that future point.",
   "metadata": {
    "tags": [],
    "cell_id": "00044-318db16a-5963-4e27-8fa5-883d34e6265e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00043-8b26b37c-3b50-46b5-9da1-3427975bb56a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1828c724",
    "execution_start": 1639085356986,
    "execution_millis": 19996,
    "deepnote_cell_type": "code"
   },
   "source": "collector2.simulate()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Next we can momentarily forget about rotation and think about target translation. Now the target will have some initial linear velocity and iiwa must effectively intercept the target in its trajectory. Because the target is free-floating in empty space, we can reuse a lot of the previous infrastructure for the motion planning by precomputing the predicted state of the target at the intercept point. Although it's messy, I will modify make_gripper_frames below to server the initial linear velocity case. ",
   "metadata": {
    "tags": [],
    "cell_id": "00046-dff894e2-7164-4fde-a4f1-8508e5ce2bdd",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00047-07373c57-6268-45df-a754-092c6f2441bc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7ea11825",
    "execution_start": 1639085376991,
    "execution_millis": 15,
    "deepnote_cell_type": "code"
   },
   "source": "def make_gripper_frames_lin(X_G, X_O, target_clearance=np.array([0.0, 0.08, 0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=20, v_target=0.05):\n  \"\"\"\n  Takes a partial specification with X_G[\"initial\"] and X_O[\"initial\"] and X_0[\"goal\"], and \n  returns a X_G and times with all of the pick and place frames populated.\n  \"\"\"\n  # Define (again) the gripper pose relative to the object when in grasp.\n  p_GgraspO = target_clearance\n  R_GgraspO = R_GgraspTarget\n  # R_GgraspO = RotationMatrix.MakeZRotation(np.pi/2) #.MakeZRotation(-np.pi/4).inverse()\n  X_GgraspO = RigidTransform(R_GgraspO, p_GgraspO)\n  X_OGgrasp = X_GgraspO.inverse()\n  # pregrasp is negative y in the gripper frame (see the figure!).\n  X_GgraspGpregrasp = RigidTransform(p=[0, -0.2, 0])\n\n  X_G[\"pick\"] = X_O[\"initial\"].multiply(X_OGgrasp)\n  X_G[\"prepick\"] = X_G[\"pick\"].multiply(X_GgraspGpregrasp)\n  X_G[\"adjusted\"] = X_G[\"prepick\"]\n  X_G[\"postpick\"] = X_G[\"pick\"]\n\n  # Now let's set the timing\n  times = {\"initial\": 0}\n  delay_time = 3.0\n  X_GinitialGprepick = X_G[\"initial\"].inverse().multiply(X_G[\"prepick\"])\n  times[\"prepick\"] = times[\"initial\"] + t_catch - delay_time # 15.0*np.linalg.norm(X_GinitialGprepick.translation())\n  times[\"adjusted\"] = times[\"prepick\"] + 1e-5\n  # Allow some time for the gripper to close.\n  times[\"pick_start\"] = times[\"adjusted\"] + delay_time + 5.0 * v_target\n  times[\"pick_end\"] = times[\"pick_start\"] + 0.5 # 2.0\n  times[\"postpick\"] = times[\"pick_end\"] + 0.5 # 2.0\n\n  return X_G, times",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00047-b5ab8112-4852-4690-b035-4bc6ea1de8fd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7c0c2908",
    "execution_start": 1639085377108,
    "execution_millis": 344,
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize target and motion plan\n\n# p_target = np.array([0.6,0.6,0.8])\np_target = np.array([0.55,0.55,0.8])\nR_target = RotationMatrix()\nw_target = [0.0,0.0,0.0]\nv_target = [0.0,-0.01,0.0]\nX_WT_init=RigidTransform(R_target, p_target) \nV_WT_init=SpatialVelocity(w_target, v_target)\n\n# Set time of target capture from start of trajectory \nt_catch = 10 # in seconds\n\n# Predict where the target will be after t_catch\np_target_intercept = p_target + np.array(v_target) * t_catch \n\nX_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\nX_G = {\"initial\": X_WorldGripper_init}\nX_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\nX_G, times = make_gripper_frames_lin(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n# print(times)\n\n# print(X_G)\n# print(times)\nprint(f\"Sanity check: The entire maneuver will take {times['postpick']} seconds to execute.\")\nvisualize_gripper_frames(X_G, X_O)\ntraj_p_G = make_gripper_position_trajectory(X_G, times)\ntraj_R_G = make_gripper_orientation_trajectory(X_G, times)\ntraj_wsg_command = make_wsg_command_trajectory(times)\ntraj = PiecewisePose(traj_p_G, traj_R_G)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Sanity check: The entire maneuver will take 11.05001 seconds to execute.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00048-87077e71-3079-4575-a9ff-afb24fe67bfc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "51eca66a",
    "execution_start": 1639085377460,
    "execution_millis": 546,
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize collector (now IIWACollector2)\n\nmeshcat.Delete()\ncollector3 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT_init, V_WT=V_WT_init)\n\n# collector.short_sim()\ndiagram = collector3.get_diagram()\n# display(SVG(pydot.graph_from_dot_data(diagram.GetGraphvizString())[0].create_svg()))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00049-1cf9bfe6-54c1-4cdd-841d-de3dddca9e15",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "26f1df9e",
    "execution_start": 1639085378020,
    "execution_millis": 12003,
    "deepnote_cell_type": "code"
   },
   "source": "collector3.simulate_with_duration(t_catch + 2.0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now, let's combine the initial rotation and translation rates.",
   "metadata": {
    "tags": [],
    "cell_id": "00051-4db946fd-1b4f-4917-8440-d205b2db07c8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00052-7f9f03f8-9a0b-486f-b41b-9e9405447695",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1c0f0140",
    "execution_start": 1639085390039,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "def make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0, 0.08, 0.0]), R_GgraspTarget=RotationMatrix.MakeYRotation(np.pi).MakeZRotation(-np.pi/4).inverse(), t_catch=20, v_target=0.05):\n  \"\"\"\n  Takes a partial specification with X_G[\"initial\"] and X_O[\"initial\"] and X_0[\"goal\"], and \n  returns a X_G and times with all of the pick and place frames populated.\n  \"\"\"\n  # Define (again) the gripper pose relative to the object when in grasp.\n  p_GgraspO = target_clearance\n  R_GgraspO = R_GgraspTarget\n  # R_GgraspO = RotationMatrix.MakeZRotation(np.pi/2) #.MakeZRotation(-np.pi/4).inverse()\n  X_GgraspO = RigidTransform(R_GgraspO, p_GgraspO)\n  X_OGgrasp = X_GgraspO.inverse()\n  # pregrasp is negative y in the gripper frame (see the figure!).\n  X_GgraspGpregrasp = RigidTransform(p=[0, -0.2, 0])\n\n  X_G[\"pick\"] = X_O[\"initial\"].multiply(X_OGgrasp)\n  X_G[\"prepick\"] = X_G[\"pick\"].multiply(X_GgraspGpregrasp)\n  X_G[\"adjusted\"] = X_G[\"prepick\"]\n  X_G[\"postpick\"] = X_G[\"pick\"]\n\n  # Now let's set the timing\n  times = {\"initial\": 0}\n  delay_time = 3.0\n  X_GinitialGprepick = X_G[\"initial\"].inverse().multiply(X_G[\"prepick\"])\n  times[\"prepick\"] = times[\"initial\"] + t_catch - delay_time # 15.0*np.linalg.norm(X_GinitialGprepick.translation())\n  times[\"adjusted\"] = times[\"prepick\"] + 1e-5\n  # Allow some time for the gripper to close.\n  times[\"pick_start\"] = times[\"adjusted\"] + delay_time + 5.0 * v_target\n  times[\"pick_end\"] = times[\"pick_start\"] + 0.5 # 2.0\n  times[\"postpick\"] = times[\"pick_end\"] + 0.5 # 2.0\n\n  return X_G, times",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00053-d7d9e905-039a-4605-af5b-98e8b019e1f9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "87e56bd9",
    "execution_start": 1639085390040,
    "execution_millis": 455,
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize target and motion plan\n\n# p_target = np.array([0.6,0.6,0.8])\np_target = np.array([0.55,0.55,0.8])\nR_target = RotationMatrix()\nw_target = [0.05,0.05,0.0]\nv_target = [0.0,-0.01,0.0]\nX_WT_init=RigidTransform(R_target, p_target) \nV_WT_init=SpatialVelocity(w_target, v_target)\n\n# Set time of target capture from start of trajectory \nt_catch = 10 # in seconds, try 15 for a really extended catch!\n\n# Predict where the target will be after t_catch\np_target_intercept = p_target + np.array(v_target) * t_catch \n\nX_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\nX_G = {\"initial\": X_WorldGripper_init}\nX_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\nX_G, times = make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n# print(times)\n\n# print(X_G)\n# print(times)\nprint(f\"Sanity check: The entire maneuver will take {times['postpick']} seconds to execute.\")\nvisualize_gripper_frames(X_G, X_O)\ntraj_p_G = make_gripper_position_trajectory(X_G, times)\ntraj_R_G = make_gripper_orientation_trajectory(X_G, times)\ntraj_wsg_command = make_wsg_command_trajectory(times)\ntraj = PiecewisePose(traj_p_G, traj_R_G)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Sanity check: The entire maneuver will take 11.05001 seconds to execute.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00054-8e524093-6025-4525-8838-aff05282a146",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9529a6bb",
    "execution_start": 1639085390677,
    "execution_millis": 378,
    "deepnote_cell_type": "code"
   },
   "source": "# Re-initialize collector (now IIWACollector2)\n\nmeshcat.Delete()\ncollector4 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT_init, V_WT=V_WT_init)\n\n# collector.short_sim()\ndiagram = collector4.get_diagram()\n# display(SVG(pydot.graph_from_dot_data(diagram.GetGraphvizString())[0].create_svg()))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00055-0c8dde22-a8ef-4574-a355-d146bdba0818",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "da841dcb",
    "execution_start": 1639085391080,
    "execution_millis": 11978,
    "deepnote_cell_type": "code"
   },
   "source": "collector4.simulate_with_duration(t_catch + 2.0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Experiments with target initial conditions",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00051-22ebba3a-07cb-47e9-b116-dd887a6e3919",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "The main experiments that are conducted here are separated by case:\n- Case 1: Catching a rotating target\n- Case 2: Catching a translating target\n- Case 3: Catching a rotating and translating target\n- Case 4: Catching a rotating and translating target (fixed velocities) with varying initial target positions\n\nUnder Case 1, we can test the following initial angular velocities (in rad/s):\n- omega_target = 0.01\n- omega_target = 0.05\n- omega_target = 0.1\n- omega_target = 0.2\n- omega_target = 0.5\n\nUnder Case 2, we can test the following initial linear velocities (in m/s):\n- v_target = 0.01 \n- v_target = 0.05\n- v_target = 0.1\n- v_target = 0.2\n- v_target = 0.5\n\nUnder Case 3, we can test the following conditions (angular velocity: rad/s, linear velocity: m/s):\n- 0.01, 0.01\n- 0.05, 0.01\n- 0.1, 0.01\n- 0.1, 0.1\n- 0.2, 0.2\n\nUnder Case 4, we can test the following conditions (position vector):\n- 0.7,0.7,0.8\n- 0.1,0.1,0.1\n- -0.55,-0.55,0.8",
   "metadata": {
    "tags": [],
    "cell_id": "00052-d0cf0103-9000-4cef-92d6-4193d179a3e4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00053-d349d06b-c827-4fc7-b1a7-2fb418043a37",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d09ab070",
    "execution_start": 1639085403077,
    "execution_millis": 18,
    "deepnote_output_heights": [
     578,
     606.1875
    ],
    "deepnote_cell_type": "code"
   },
   "source": "def case_1_test(omega_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix()):\n    w_target = [omega_target,omega_target,0.0]\n    v_target = [0.0,0.0,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT, \"goal\": X_WT}\n    X_G, new_times = make_gripper_frames(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, new_times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, new_times)\n    traj_wsg_command = make_wsg_command_trajectory(new_times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case1 = IIWACollector2(traj=traj, poses=X_G, times=new_times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case1.simulate()\n\ncase1_test_conditions = [0.01, 0.05, 0.1, 0.2, 0.5]\n# for w in case1_test_conditions:\n#     case_1_test(w)\n#     time.sleep(2)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00054-de80d0a5-39ef-4ef7-9506-b56c7093ba21",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2d9863f4",
    "execution_start": 1639085403108,
    "execution_millis": 6,
    "deepnote_output_heights": [
     606.1875
    ],
    "is_code_hidden": false,
    "deepnote_cell_type": "code"
   },
   "source": "def case_2_test(v_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix(), t_catch=10):\n    R_target_test = RotationMatrix.MakeZRotation(np.pi/4)\n    w_target = [0.0, 0.0, 0.0]\n    v_target = [0.0, v_target,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n    X_WT_test=RigidTransform(R_target_test, p_target)\n\n    # Predict where the target will be after t_catch\n    p_target_intercept = p_target + np.array(v_target) * t_catch \n\n    X_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\n\n    X_G, times = make_gripper_frames_lin(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, times)\n    traj_wsg_command = make_wsg_command_trajectory(times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case2 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case2.simulate()\n\ncase2_test_conditions = [0.01, 0.05, 0.1, 0.2, 0.5]\n# for w in case2_test_conditions:\n#     case_2_test(-w)\n#     time.sleep(2)\n\n# Got a failure with v_target = 0.5, try changing t_catch\n# case_2_test(-0.5, t_catch=5)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00055-17d2b7df-a3e9-48ee-99d0-7ca0e7bb8b7f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c1b06e65",
    "execution_start": 1639085403126,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "def case_3_test(omega_target, v_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix(), t_catch=10):\n    R_target_test = RotationMatrix.MakeZRotation(np.pi/4)\n    w_target = [omega_target, omega_target, 0.0]\n    v_target = [0.0, v_target,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n    X_WT_test=RigidTransform(R_target_test, p_target)\n\n    # Predict where the target will be after t_catch\n    p_target_intercept = p_target + np.array(v_target) * t_catch \n\n    X_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\n\n    X_G, times = make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, times)\n    traj_wsg_command = make_wsg_command_trajectory(times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case3 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case3.simulate()\n\ncase3_test_conditions = [(0.01, 0.01), (0.05, 0.01), (0.1, 0.01), (0.1, 0.05), (0.2, 0.2)]\n# for w in case3_test_conditions:\n#     case_3_test(w[0], -w[1])\n#     time.sleep(2)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00061-035c8001-c8c3-4e31-b67d-2751bb2ec7d7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fddd35a8",
    "execution_start": 1639085403143,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": "def case_4_test(omega_target, v_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix(), R_GgraspObject=RotationMatrix().MakeZRotation(np.pi/2), t_catch=10):\n    R_target_test = RotationMatrix.MakeZRotation(np.pi/4)\n    w_target = [omega_target, omega_target, 0.0]\n    v_target = [v_target, 0.0,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n    X_WT_test=RigidTransform(R_target_test, p_target)\n\n    # Predict where the target will be after t_catch\n    p_target_intercept = p_target + np.array(v_target) * t_catch \n\n    X_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\n\n    X_G, times = make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=R_GgraspObject, t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, times)\n    traj_wsg_command = make_wsg_command_trajectory(times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case4 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case4.simulate()\n\ncase4_test_conditions = [[-0.3, 0.3, 0.8], [0.5, 0.5, 0.2], [0.55, 0.55, 0.8]]\ncase4_Rgrasps = [RotationMatrix() for i in range(len(case4_test_conditions))]\n# for i,w in enumerate(case4_test_conditions):\n#     case_4_test(0.1, -0.025, p_target=np.array(w), R_GgraspObject=case4_Rgrasps[i])\n#     time.sleep(2)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Adding random noise",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00052-6a97dee7-1a34-4063-870f-ec54f0af563c",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "$w\\in\\mathbb{R}^2$ is drawn from a Gaussian distribution, $w\\sim\\mathcal{N}(0,\\sigma^2=0.25)$. ",
   "metadata": {
    "tags": [],
    "cell_id": "00063-728b90a8-a071-4d0a-8138-263ff70579d4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Add noise to initial target pose estimate",
   "metadata": {
    "tags": [],
    "cell_id": "00064-07175816-9624-43de-b8c1-e550c7f3e548",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00063-506db642-48be-4619-b045-721a95305e71",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ef121dbd",
    "execution_start": 1639085694370,
    "execution_millis": 108103,
    "deepnote_cell_type": "code"
   },
   "source": "def case_5_test(omega_target, v_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix(), t_catch=10):\n    R_target_test = RotationMatrix.MakeZRotation(np.pi/4)\n    w_target = [omega_target, omega_target, 0.0]\n    v_target = [0.0, v_target,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n    X_WT_test=RigidTransform(R_target_test, p_target)\n\n    # Predict where the target will be after t_catch\n    # Now add noisy kick\n    w = np.random.normal(0.0, scale=np.sqrt(0.001), size=(3,))\n    print(p_target)\n    print(p_target + w)\n    p_target_intercept = (p_target + w) + np.array(v_target) * t_catch \n\n    X_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\n\n    X_G, times = make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, times)\n    traj_wsg_command = make_wsg_command_trajectory(times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case5 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case5.simulate()\n\ncase5_test_conditions = [(0.01, 0.01), (0.05, 0.01), (0.1, 0.01), (0.1, 0.05), (0.2, 0.2)]\nfor w in case5_test_conditions:\n    case_5_test(w[0], -w[1])\n    time.sleep(1)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[0.55 0.55 0.8 ]\n[0.52715706 0.51705713 0.82435884]\n[0.55 0.55 0.8 ]\n[0.59628263 0.5269974  0.80450566]\n[0.55 0.55 0.8 ]\n[0.56876058 0.55889461 0.78358158]\n[0.55 0.55 0.8 ]\n[0.57381008 0.4927869  0.7886319 ]\n[0.55 0.55 0.8 ]\n[0.54286577 0.53522889 0.75482905]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Add noise to initial linear velocity estimate",
   "metadata": {
    "tags": [],
    "cell_id": "00066-64704536-b805-42fa-af4a-72c34363ecc0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00067-9aa63cf3-b2ff-4466-8e04-2af9cb100911",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fe391d77",
    "execution_start": 1639086223077,
    "execution_millis": 107823,
    "deepnote_cell_type": "code"
   },
   "source": "def case_6_test(omega_target, v_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix(), t_catch=10):\n    R_target_test = RotationMatrix.MakeZRotation(np.pi/4)\n    w_target = [omega_target, omega_target, 0.0]\n    v_target = [0.0, v_target,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n    X_WT_test=RigidTransform(R_target_test, p_target)\n\n    w = np.random.normal(0.0, scale=np.sqrt(0.001), size=(3,))\n    w[0] = 0\n    w[2] = 0\n\n    # Predict where the target will be after t_catch\n    # Now add noisy kick to linear velocity estimate as a 'model' for a continuous pose estimate with noise\n    print(v_target)\n    print(v_target + w)\n    p_target_intercept = (p_target) + np.array(v_target + w) * t_catch \n\n    X_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\n\n    X_G, times = make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target+w)))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, times)\n    traj_wsg_command = make_wsg_command_trajectory(times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case6 = IIWACollector2(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case6.simulate()\n\ncase6_test_conditions = [(0.01, 0.01), (0.05, 0.01), (0.1, 0.01), (0.1, 0.05), (0.2, 0.2)]\nfor w in case6_test_conditions:\n    case_6_test(w[0], -w[1])\n    time.sleep(1)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[0.0, -0.01, 0.0]\n[ 0.         -0.01522328  0.        ]\n[0.0, -0.01, 0.0]\n[ 0.         -0.01060131  0.        ]\n[0.0, -0.01, 0.0]\n[ 0.         -0.00554668  0.        ]\n[0.0, -0.05, 0.0]\n[ 0.         -0.04737083  0.        ]\n[0.0, -0.2, 0.0]\n[ 0.         -0.10738168  0.        ]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Add noise to initial angular velocity estimate. To do this I need to modify the CollectorPlanner a bit and then modify the IIWACollector class yet again. ",
   "metadata": {
    "tags": [],
    "cell_id": "00067-17d4004c-6467-4ca5-8eff-4af5377363e6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00069-4a61c52a-8183-48d0-8764-a59cd9845af5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "764230bd",
    "execution_start": 1639087290030,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "class NoisyCollectorPlanner(LeafSystem):\n    ''' Effectively acts as a custom TrajectorySource\n    '''\n    def __init__(self, plant, traj, poses, times, output_vel):\n        LeafSystem.__init__(self)\n        self._plant = plant\n        self._plant_context = plant.CreateDefaultContext()\n        self._iiwa = plant.GetModelInstanceByName(\"iiwa7\")\n        self._G = plant.GetBodyByName(\"body\").body_frame()\n        self._W = plant.world_frame()\n        \n        assert traj.cols() == 1\n        port = self.DeclareVectorOutputPort(\"value\", traj.rows(), self.CalcOutput)\n        port.disable_caching_by_default()\n        self.w_x_port = self.DeclareVectorInputPort(\"target_rotation_rate_x\", BasicVector(1))\n        self.w_y_port = self.DeclareVectorInputPort(\"target_rotation_rate_y\", BasicVector(1))\n        self.w_z_port = self.DeclareVectorInputPort(\"target_rotation_rate_z\", BasicVector(1))\n        # Keep the trajectory as undeclared state\n        self.traj = traj\n        self.match_time = times['adjusted']\n        self.updated = False\n        self.w_cyl = None\n        self.R_WG_adjusted = poses['adjusted'].rotation()\n        self.w = np.random.normal(0.0, scale=np.sqrt(0.001), size=(3,))\n        self.w[2] = 0\n\n        # Flag to see whether outputting linear or angular velocities\n        self.output_vel = output_vel\n\n    def get_X_WG(self):\n\n        X_WG = self._plant.CalcRelativeTransform(\n                    self._plant_context,\n                    frame_A=self._W,\n                    frame_B=self._G)\n        return X_WG\n\n    def CalcOutput(self, context, output):\n        # Note: you can add input ports and read their values here.\n        if (context.get_time() >= times['pick_end']):\n            output.SetFromVector(self.traj.value(context.get_time()))\n        elif (context.get_time() >= self.match_time):\n            target_ang_vel_x = self.w_x_port.Eval(context)\n            target_ang_vel_y = self.w_y_port.Eval(context)\n            target_ang_vel_z = self.w_z_port.Eval(context)\n            target_ang_vel = np.array([target_ang_vel_x[0], target_ang_vel_y[0], target_ang_vel_z[0]])\n            # print(target_ang_vel)\n\n            # If outputting linear velocity\n            if self.output_vel:\n                lin_vel = np.array([0.0, 0.0, 0.0])\n                # output.SetFromVector(lin_vel)\n                output.SetFromVector(self.traj.value(context.get_time()))\n            # Else if outputting angular velocity\n            else:\n                if self.w_cyl is None:\n                    self.w_cyl = np.linalg.norm(target_ang_vel + self.w)\n                    print('Noisy rate measurement: ' + str(self.w_cyl))\n                ang_vel_y_G = (self.w_cyl * times['adjusted'] + self.w_cyl * (times['pick_start'] - times['adjusted'])) / (times['pick_start'] - times['adjusted'])\n                ang_vel_G = np.array([0, ang_vel_y_G, 0.0])\n                ang_vel = self.R_WG_adjusted.multiply(ang_vel_G)\n                # print(ang_vel)\n                output.SetFromVector(ang_vel)\n        else:\n            output.SetFromVector(self.traj.value(context.get_time()))\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00070-dc65dc41-c5ed-47ef-8c7f-1526d6a89ccd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ffbbf2d1",
    "execution_start": 1639087292619,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "class IIWACollector3():\n    def __init__(self, traj=None, poses=None, times=None, traj_wsg=None, X_WT=RigidTransform(p=[1.0,0,1.0]), V_WT=SpatialVelocity(w=[0.0,0.0,0.0], v=[0.0,0.0,0.0])):\n        builder = DiagramBuilder()\n        # set up the system of manipulation station\n        station_diagram, self.plant = MakeManipulationStation()\n        self.station = builder.AddSystem(station_diagram)\n        self.iiwa_model_instance = self.plant.GetModelInstanceByName(\"iiwa7\")\n        self.X_WT=X_WT\n        self.V_WT=V_WT\n\n        # optionally add trajectory source\n        if traj is not None:\n            traj_v_G = traj.get_position_trajectory().MakeDerivative()\n            traj_w_G = traj.get_orientation_trajectory().MakeDerivative()\n            v_G_source = builder.AddSystem(NoisyCollectorPlanner(self.plant, traj_v_G, poses, times, True))\n            w_G_source = builder.AddSystem(NoisyCollectorPlanner(self.plant, traj_w_G, poses, times, False))\n            self.controller = builder.AddSystem(PseudoInverseController(self.plant))\n            builder.Connect(v_G_source.get_output_port(), self.controller.GetInputPort(\"v_G\"))\n            builder.Connect(w_G_source.get_output_port(), self.controller.GetInputPort(\"w_G\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_x\"), v_G_source.GetInputPort(\"target_rotation_rate_x\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_x\"), w_G_source.GetInputPort(\"target_rotation_rate_x\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_y\"), v_G_source.GetInputPort(\"target_rotation_rate_y\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_y\"), w_G_source.GetInputPort(\"target_rotation_rate_y\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_z\"), v_G_source.GetInputPort(\"target_rotation_rate_z\"))\n            builder.Connect(self.station.GetOutputPort(\"target_angular_vel_z\"), w_G_source.GetInputPort(\"target_rotation_rate_z\"))\n            self.integrator = builder.AddSystem(Integrator(7))\n            builder.Connect(self.controller.get_output_port(), \n                        self.integrator.get_input_port())\n            builder.Connect(self.integrator.get_output_port(),\n                            self.station.GetInputPort(\"iiwa_position\"))\n            builder.Connect(self.station.GetOutputPort(\"iiwa_position_measured\"),\n                            self.controller.GetInputPort(\"iiwa_position\"))\n        # handle gripper velocity matching\n            \n        if traj_wsg is not None:\n            wsg_source = builder.AddSystem(TrajectorySource(traj_wsg))\n            wsg_source.set_name(\"wsg_command\")\n            builder.Connect(wsg_source.get_output_port(), self.station.GetInputPort(\"wsg_position\"))\n        else:\n            wsg_position = builder.AddSystem(ConstantVectorSource([0.1]))\n            builder.Connect(wsg_position.get_output_port(), self.station.GetInputPort(\"wsg_position\"))\n\n        params = MeshcatVisualizerParams()\n        params.delete_on_initialization_event = False\n        self.visualizer = MeshcatVisualizerCpp.AddToBuilder(\n            builder, self.station.GetOutputPort(\"geometry_query\"), meshcat, params)\n\n        self.diagram = builder.Build()\n        self.gripper_frame = self.plant.GetFrameByName('body')\n        self.world_frame = self.plant.world_frame()\n\n        context = self.CreateDefaultContext()\n        self.diagram.Publish(context)\n\n    def visualize_frame(self, name, X_WF, length=0.15, radius=0.006):\n        \"\"\"\n        visualize imaginary frame that are not attached to existing bodies\n        \n        Input: \n            name: the name of the frame (str)\n            X_WF: a RigidTransform to from frame F to world.\n        \n        Frames whose names already exist will be overwritten by the new frame\n        \"\"\"\n        AddMeshcatTriad(meshcat, \"painter/\" + name,\n                        length=length, radius=radius, X_PT=X_WF)\n\n    def CreateDefaultContext(self):\n        context = self.diagram.CreateDefaultContext()\n        plant_context = self.diagram.GetMutableSubsystemContext(self.plant,   context)\n        station_context = self.diagram.GetMutableSubsystemContext(self.station, context)\n        # station_context = self.station.GetMyContextFromRoot(self.simulator.get_mutable_context())\n        \n        # provide initial states\n        q0 = np.array([ 1.40666193e-05,  1.56461165e-01, -3.82761069e-05, \n                       -1.32296976e+00, -6.29097287e-06,  1.61181157e+00, -2.66900985e-05])\n        \n        # set the joint positions of the kuka arm\n        self.plant.SetPositions(plant_context, self.iiwa_model_instance, q0)\n\n        # Set target's initial condition (pose and spatial velocity)\n        target = self.plant.GetBodyByName('target')\n        self.plant.SetFreeBodyPose(plant_context, target, X_WB=self.X_WT)\n        self.plant.SetFreeBodySpatialVelocity(context=plant_context, body=target, V_WB=self.V_WT)\n\n        if hasattr(self, 'integrator'):\n            self.integrator.set_integral_value(\n                self.integrator.GetMyMutableContextFromRoot(context), \n                self.plant.GetPositions(plant_context, self.iiwa_model_instance))\n\n        return context\n    \n    def get_X_WG(self, context=None):\n\n        if not context:\n            context = self.CreateDefaultContext()\n        plant_context = self.plant.GetMyMutableContextFromRoot(context)\n        X_WG = self.plant.CalcRelativeTransform(\n                    plant_context,\n                    frame_A=self.world_frame,\n                    frame_B=self.gripper_frame)\n        return X_WG\n\n    def simulate(self):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = 20.0 if running_as_notebook else 0.01\n        simulator.AdvanceTo(duration)\n\n    def simulate_with_duration(self, tiempo):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = tiempo if running_as_notebook else 0.01\n        simulator.AdvanceTo(duration)\n\n    def short_sim(self):\n        context = self.CreateDefaultContext()\n        simulator = Simulator(self.diagram, context)\n        simulator.set_target_realtime_rate(1.0)\n\n        duration = 5\n        simulator.AdvanceTo(duration)\n\n    def get_target_location(self):\n        return self.X_WT.p, self.X_WT.R\n\n    def get_diagram(self):\n        return self.diagram",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00071-a1ea1173-1b4e-4713-91ea-f644c76d5482",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2794bda7",
    "execution_start": 1639087296995,
    "execution_millis": 108445,
    "deepnote_output_heights": [
     578
    ],
    "deepnote_cell_type": "code"
   },
   "source": "def case_7_test(omega_target, v_target, p_target=np.array([0.55,0.55,0.8]), R_target=RotationMatrix(), t_catch=10):\n    R_target_test = RotationMatrix.MakeZRotation(np.pi/4)\n    w_target = [omega_target, omega_target, 0.0]\n    v_target = [0.0, v_target,0.0]\n    X_WT=RigidTransform(R_target, p_target) \n    V_WT=SpatialVelocity(w_target, v_target)\n    X_WT_test=RigidTransform(R_target_test, p_target)\n\n    # Predict where the target will be after t_catch\n    # Now add noisy kick to linear velocity estimate as a 'model' for a continuous pose estimate with noise\n    p_target_intercept = (p_target) + np.array(v_target) * t_catch \n\n    X_WT_intercept = RigidTransform(R_target, p_target_intercept)\n\n    X_G = {\"initial\": X_WorldGripper_init}\n    X_O = {\"initial\": X_WT_intercept, \"goal\": X_WT_intercept}\n\n    X_G, times = make_gripper_frames_combo(X_G, X_O, target_clearance=np.array([0.0,0.1,0.0]), R_GgraspTarget=RotationMatrix().MakeZRotation(np.pi/2), t_catch=t_catch, v_target=np.linalg.norm(np.array(v_target)))\n\n    traj_p_G = make_gripper_position_trajectory(X_G, times)\n    traj_R_G = make_gripper_orientation_trajectory(X_G, times)\n    traj_wsg_command = make_wsg_command_trajectory(times)\n    traj = PiecewisePose(traj_p_G, traj_R_G)\n\n    meshcat.Delete()\n    collector_case7 = IIWACollector3(traj=traj, poses=X_G, times=times, traj_wsg=traj_wsg_command, X_WT=X_WT, V_WT=V_WT)\n\n    collector_case7.simulate()\n\ncase7_test_conditions = [(0.01, 0.01), (0.05, 0.01), (0.1, 0.01), (0.1, 0.05)]\nfor w in case7_test_conditions:\n    case_7_test(w[0], -w[1])\n    time.sleep(1)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Noisy rate measurement: 0.043001498610295646\nNoisy rate measurement: 0.03197766153912803\nNoisy rate measurement: 0.2118509389350274\nNoisy rate measurement: 0.11819056674743751\nNoisy rate measurement: 0.284494229279346\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Future Improvements",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00058-81816261-9ddb-4a0c-9c63-b97eeb17c543",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=52fe2c12-5462-4de8-b3a8-e001ac600845' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Robotic Manipulation - Force Control.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "deepnote_notebook_id": "0d9f36dc-179c-492c-b558-c57bc82d5a73",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}